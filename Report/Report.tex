\documentclass[12pt]{article}
\usepackage[a4paper, margin=0.8in]{geometry}
\pdfpagewidth 8.5in
\pdfpageheight 11.0in
\textheight 9.7in
\usepackage{color} %used for font color
\usepackage{amssymb, amsmath, multirow, commath, inputenc, titling, epic, paralist, graphicx, algorithm,algorithmic, tikz, xcolor,colortbl, environ, quoting, ragged2e, lipsum, caption}

\usepackage{sectsty}
\usepackage{multicol}
\sectionfont{\large}

\setlength{\droptitle}{-5.5em}
\setlength{\parindent}{30pt}

\begin{document}

\title{{\bf \large Utilizing an AI Approach to Pathfinding in Super Mario}\vspace{-2ex}}
\author{{\small Nick De Tullio, Michael Jalkio, \& Thomas Gautier}
\\ {\small nrd24@cornell.edu, mrj77@cornell.edu, tng26@cornell.edu}\vspace{-9ex}}
\date{}

\maketitle

\section * {Abstract}
This paper utilizes the Mario AI benchmark, to describe the success of both previously implemented Mario bots 
compared to our own implementation. The Mario AI Benchmark was introduced for use first in the IEEE Games 
Innovation Conference (ICE-GIC) and then later in Computational Intelligence Games (CIG) as a benchmark for 
reinforcement learning algorithms and other game AI techniques in a public domain clone of the platform game {\it 
Super Mario Bros}. Each year the CIG conducts a Mario AI Competition, in which they compare contestants 
submitted Mario bots to this benchmark. The goal of this paper is to determine the success of bots that were already 
created for this competition and then to decide whether an improved bot can be created. The bots that will be 
evaluated fell into three categories in the competitions A*-based, learning-based, and rule-based implementations.

\setlength{\columnsep}{.65cm}
\begin{multicols}{2}
\section * {Introduction}
A platform game, or platformer, is a video game which involves guiding an avatar to jump between suspended 
platforms, over obstacles, or both in order to advance the game. These challenges are known as jumping puzzles 
or freerunning. It is the job of the player to control the jumps in order to avoid letting their avatar fall from the 
platforms or miss the necessary jumps. The most common element of the genre of platform games is the jump 
button. Platform games originated in the early 1980s in side scrolling or 2D video games, which were eventually 
followed by 3D successors in the mid-1990s.

Super Mario Bros is a series of platform video games created by Nintendo, featuring the main character Mario who 
serves as the player's avatar. The game follows Mario's adventures in the fictional Mushroom Kingdom, where he 
runs and jumps across platforms and atop enemies in themed levels. In the game it is necessary for Mario to jump 
over enemies and between platforms. It is also beneficial to Mario to jump on enemies in order to prevent them 
from coming across his path again, provided that they do not have spiked turtle shells. Aside from staying alive and 
progressing towards the finish line, it is also beneficial to the player's score for Mario to collect coins by jumping 
into them as they are found in the level, as well as by jumping into bricks for coins that may be hidden. There are 
also a multitude of power-ups and items which give Mario special powers such as fireball-throwing, size-changing, 
and extra lives, which can also be found by jumping into bricks.

In order to make the benchmark possible the game was modified via the construction of an API that enabled it to be 
easily interfaced with learning algorithms and the various competitors' controllers. The modifications included the 
removal of the dependency on the system clock so that the learning algorithm can ``step" forward, removing the 
dependency on the graphical output, and substantial refactoring. Each step in the game corresponds to 40 
milliseconds of simulated time which has an update frequency of 25 frames per second. At each step, the controller 
receives a description of the environment, and outputs an action. The software that makes these modifications 
possible is a single threaded Java application, which allows for the key methods that a controller needs to 
implement to be specified in a single Java interface file.

There are many features that make \textit {Super Mario Bros} or platformers in general particularly interesting from 
an artificial intelligence or reinforcement learning perspective. What is likely the most important feature of the game 
is its potentially very rich and high-dimensional environment representation. When a human player views the 
game, he views a small part of the current level in two dimensions, with the screen centered on Mario. There are 
very rarely sparse views, in most cases there are dozens of objects such as brick blocks, enemies and collectable 
items. The static environment, such as grass, pipes, and brick blocks are laid out in a grid that covers 
approximately $19 * 19$ cells.

The entries for the 2009 Mario AI competition were classified into three broad categories, hard-coded heuristic, 
learning-based, and A*-based controllers. Hard-coded heuristics were the largest category, comprised of seven 
different controllers which were hand-constructed, non-adaptive, and did not use search-based methods for action 
selection. Learning based controllers were the second largest category comprised of two subcategories artificial 
evolution. There were three entries, the first used expression trees commonly used in genetic programming, the 
second evolved code for a stack-based virtual machine, and the third evolved a rule-based controller. The A*-based 
controllers were the most successful entries in the competition, beating the other controllers by a huge margin.

The success of the A*-based controllers over all other categories was considered by those running the competition 
to be a shortcoming, so in the 2010 Mario AI competition the level generator was expanded to include the possibility 
of generating dead ends. A dead end is defined as a situation where the player can choose one of two paths when 
moving forward, but at least one of the paths is blocked. This requires the player to backtrack and choose another 
path. Additionally, a number of other changes were made to the level generator in order to create harder levels. 
Some of the features introduced included greater control over numbers of items, the possibility of hidden blocks, and 
longer gaps. The difficulty was also increased for the hardest levels and some were literally impossible to finish. This 
allowed for the behaviors of various controllers to be tested in this difficult environment.

The 2010 championship allowed for both new and old competitors to enter, and there was a vast improvement in scores compared to the previous year.

\section * {Analysis of Agents}
We analyzed six different agents for this paper.  The first is the basic ForwardJumpingAgent which 
was a sample agent provided by the benchmark.  Three of the agents are the best agents within
their respective categories that were submitted 
for the CIG iteration of the competition.  There's one A* agent, one hard-coded rule based agent, and 
one learning agent.  Finally, we looked at two agents that we created.  The first was an attempt at a 
small improvement to the ForwardJumpingAgent that would jump out of holes when it fell in.  
The second was our own very simple rule based agent.

The analysis consisted of running the agents on 40 different levels.  They played 10 levels each 
on difficulties 0, 3, 5, and 10.  Each level within the set of 10 was progressively longer.  We analyzed 
the agents both quantitatively and qualitatively.  The quantitative analysis was the scoring system 
used in the competition.  It put the largest emphasis on the distance traveled, but also considers 
kills, Mario's mode (fire, large, small), time taken, and number of levels completed.  The qualitative 
analysis was simply watching the algorithms run through the levels and seeing if we could identify 
situations that they do not perform well in.  A table of our quantitative results is below:
\end{multicols}

\begin{center}
\begin{table}[h]
\resizebox{\textwidth}{!}{ 
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
\hline
Controller & D0      & D3      & D5      & D10     & Score   & Total Kills & Status & Time Left & Mode & Total \\ \hline
FJ         & 10660.2 & 2170.2  & 1994.2  & 1137.4  & 15962.0 & 71          & 9            & 6611      & 32         &     22685.0      \\ \hline
FJ2        & 8186.2  & 1859.1  & 1605.3  & 1158.7  & 12809.3 & 60          & 8            & 6470      & 31         & 19378.3   \\ \hline
GP         & 11108.5 & 2404.5  & 1397.9  & 1024.2  & 15935.2 & 99          & 10           & 6009      & 46         & 22099.2   \\ \hline
RB         & 11369.9 & 6555.2  & 3130.2  & 3291.9  & 24347.2 & 228         & 12           & 4968      & 19         & 29574.2   \\ \hline
A*         & 11628.8 & 11611.2 & 11651.2 & 11619.2 & 46510.4 & 414         & 40           & 4730      & 80         & 51774.4   \\ \hline
Amazing    & 11267.4 & 3103.8  & 2742.0  & 1199.3  & 18312.6 & 83          & 10           & 6035      & 21         & 24461.6   \\ \hline
\end{tabular}
}
\caption*{\footnotesize Controller Scores}
\end{table}
\vspace{-3ex}
\textsc{\scriptsize Results of our run of the various bots against our own controller titled amazing agent. explanation 
of column labels: fj: forward jumping, gp: genetic programming, rb: rule-base, A*: a-star search, amazing: our 
implemented agent (amazing agent), D0...D5: score at difficulty 0...5 respectively based on progress, score: sum of 
all the difficulties, status: number of levels completed, time left: sum of time remaining after each level, mode: sum of 
abilities that mario has at the end of each level, total: total score based on progress, kills, and time taken (used to 
calculate winner)}
\end{center}

\begin{multicols*}{2}
We will analyze the agents in the order of their score from the worst to the best.
\subsection*{ForwardJumpingAgent2}
The goal of ForwardJumpingAgent2 was to solve a problem faced by the original 
ForwardJumpingAgent: falling into gaps.  In this version of Mario it is possible to jump off of walls, 
so in some situations when you're falling down a gap it's possible to jump within the gap and free 
yourself.

ForwardJumpingAgent2 always keeps track of Mario's position on the x-axis and if it stays in the 
same position for a short time (signifying that it might be stuck against a wall) it attempts to jump left.  
Then if it finds itself falling for a short time again it assumes that it's on the other wall and tries to jump 
right.  When it isn't falling into this pattern, ForwardJumpingAgent2 follows the same behavior as 
the normal ForwardJumpingAgent.

What we found when scoring this agent was that it actually performed worse than 
ForwardJumpingAgent.  It completed only 8 levels (ForwardJumpingAgent completed 9), and 
traveled a shorter distance on average at all difficulty levels other than the hardest difficulty.

There were two main issues with this agent.  The first problem was that we misjudged how 
jumping off walls could help an agent.  While the ForwardJumpingAgent fell into gaps a lot, 
it very rarely fell onto the far wall within a gap.  In fact, while watching ForwardJumpingAgent2 it was 
never able to save itself from a gap, so it failed at its main purpose.

The other issue was that jumping off walls actually hurt the agent in many cases.  The most common 
case was that the agent would fail to make it over a wall in the environment on its first try, would jump 
left, and then would have to try to jump over the wall again.  In at least one case that was observed the 
agent failed to ever make it over the wall, and fell into that loop until it timed out.  In other cases the 
agent was hit by a bullet that was able to catch up to it, the agent jumped into an enemy that it had 
already passed, and the agent even jumped into gaps that it had already passed.

Overall, this naive attempt at an improvement was a failure.  We discovered that making ``small'' 
improvements to an agent can be more difficult than expected.

\subsection*{Genetic Programming Agent}
The second worst agent was a genetic programming agent created by Matthew Erickson.  
The agent used function detectors which were written by him, and the terminal nodes are a 
collection of four values.  The four values say whether the agent should go left or right, 
press jump or not, and press down or not.  He used a population of size 500 with 90\% 
crossbreeding, 9\% cloning and 1\% mutation.

The agent managed to complete 10 levels, which was better than either of the forward jumping 
agents.  However, it had very poor performance when the difficulty was 5 and 10.  Overall, it only 
did slightly worse than FowardJumpingAgent.

Watching the agent, the most interesting difference it has when compared to the other agents is 
that it quickly pushes all of the buttons on and off.  This gives the impression that while evolving 
the genetic program that there weren't many dominant ways to play.  Generally though, the agent 
simply moves forward and jumps.  It does appear to do a better job at killing enemies with both 
fire and by jumping at them.  It has also learned to wait for the piranha plants when they are outside 
of their pipes.

The main issue faced by this agent is the way that it quickly pushes all of the buttons.  This means that 
it never holds down the jump button, and can't jump over large walls or gaps.  Overall the agent 
doesn't seem to have to learned how to deal with gaps in the environment.  This is explainable, there 
are a large number of different gaps possible in Mario.  However, in most cases just jumping frequently 
works well.    Jumping kills enemies, gets over gaps, and allows you to traverse walls.  
The genetic program didn't have enough knowledge to assess why certain strategies 
worked and did not work in given situations, it just evaluated the fitness of different programs.  
Therefore, it only learned that jumping a lot was good.

The unfortunate truth of this agent was that it was the top performing learning agent in the competition 
we were assessing.  While to a human Mario is a simple game, there are many unique cases 
encountered that makes it a very hard game for an artificial intelligence agent to learn.

\end{multicols*}

\end{document}
